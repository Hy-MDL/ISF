import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), "iTransformer"))

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
from iTransformer.model.iTransformer import Model

from sklearn.metrics import mean_squared_error, mean_absolute_error

w_2013 = pd.read_csv("weather_108_2013.csv",encoding="cp949")
solar = pd.read_excel("solar_seoul.xlsx")

#ì—´ ì¶”ì¶œ
solar['date']=pd.to_datetime(solar['date'])
s_2013 = solar[solar['date'].dt.year == 2013]
s_2013['solar generation'] = s_2013['solar generation'].astype(float)
df_2013 = pd.concat([w_2013,s_2013[['solar generation']]],axis=1)
df_2013 = df_2013.select_dtypes(include=['number'])
print(s_2013.dtypes)
features = df_2013.iloc[:,3:28].values.astype(np.float32)
target = df_2013['solar generation'].values.astype(np.float32)


# 3. ì •ê·œí™”
feature_scaler = StandardScaler()
features_scaled = feature_scaler.fit_transform(features)

target_scaler = StandardScaler()
target_scaled = target_scaler.fit_transform(target.reshape(-1, 1)).squeeze()

# 4. ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±
def create_sequences(features, target, input_len=168, pred_len=24):
    X, Y = [], []
    for i in range(len(features) - input_len - pred_len):
        X.append(features[i:i+input_len])  
        Y.append(target[i+input_len:i+input_len+pred_len])  
    return np.array(X), np.array(Y)

X, Y = create_sequences(features_scaled, target_scaled)

print(np.isnan(X).sum())
print(np.isnan(Y).sum())

# NaN ê°’ì„ ê° íŠ¹ì„±(feature)ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
nan_indices = np.isnan(X)  # NaN ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŒ
col_mean = np.nanmean(X, axis=0)  # ê° ì—´ì˜ í‰ê· ê°’ êµ¬í•˜ê¸°
X[nan_indices] = np.take(col_mean, np.nonzero(nan_indices)[1])  # NaN ê°’ì„ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´

print("ëŒ€ì²´ í›„")
print(np.isnan(X).sum())
print(np.isnan(Y).sum())

# 5. Yì˜ ì°¨ì› ë³€ê²½: (batch, 24, 1)
Y = Y[..., np.newaxis]

print("ì…ë ¥ X shape:", X.shape)
print("ì¶œë ¥ Y shape:", Y.shape)  

class SolarDataset(Dataset):
    def __init__(self, X, Y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.Y = torch.tensor(Y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
dataset = SolarDataset(X, Y)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
input_len = 168
pred_len = 24
num_features = 25

class Config:
    def __init__(self):
        self.seq_len = input_len         # = 168
        self.pred_len = pred_len         # = 24
        self.output_attention = False
        self.use_norm = True
        self.d_model = 512
        self.embed = 'timeF'
        self.freq = 'h'
        self.dropout = 0.1
        self.class_strategy = None       # í˜¹ì€ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ì„¤ì •
        self.factor = 5                  # FullAttentionì—ì„œ ì“°ëŠ” ê°’
        self.n_heads = 8
        self.e_layers = 2
        self.d_ff = 2048
        self.activation = 'gelu'

configs = Config()
model = Model(configs)

# 1. DataLoader ì¤€ë¹„ (ì´ë¯¸ ìˆëŠ” datasetì„ ì‚¬ìš©)
dataset = SolarDataset(X, Y)  # Xì™€ YëŠ” ì´ë¯¸ ì¤€ë¹„ëœ featureì™€ íƒ€ê²Ÿ ë°ì´í„°
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# 2. DataLoaderì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ë°›ê¸°
for X_batch, Y_batch in dataloader:
    # X_batchëŠ” ëª¨ë¸ ì…ë ¥ ë°ì´í„° (features)
    # Y_batchëŠ” ëª¨ë¸ ì¶œë ¥ ë°ì´í„° (íƒ€ê²Ÿ)

    # x_encëŠ” X_batchì™€ ë™ì¼í•˜ê²Œ, x_mark_encëŠ” ì‹œê°„ ì •ë³´ ë“±ì„ ë„£ì–´ì¤˜ì•¼ í•¨
    x_enc = X_batch  # ì—¬ê¸°ì„œëŠ” X_batch ê·¸ëŒ€ë¡œ ì‚¬ìš©
    x_mark_enc = torch.ones(x_enc.shape[0], x_enc.shape[1], 1)  # ì‹œê°„ ì •ë³´ëŠ” ì˜ˆì‹œë¡œ 1ë¡œ ì±„ì›€
    x_dec = torch.zeros_like(x_enc)  # ì˜ˆì¸¡ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ì´ˆê¸°í™”
    x_mark_dec = torch.ones(x_dec.shape[0], 24, 1)  # ì˜ˆì¸¡ ê¸¸ì´ì¸ 24ë¡œ ì„¤ì •

    # 3. ëª¨ë¸ì— ë°°ì¹˜ ë°ì´í„° ë„£ê³  ì‹¤í–‰
    outputs = model(x_enc, x_mark_enc, x_dec, x_mark_dec)

    # 4. ì´í›„ì— outputsë¡œ ì›í•˜ëŠ” ì‘ì—…ì„ í•  ìˆ˜ ìˆìŒ (ì˜ˆ: loss ê³„ì‚°, ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ ë“±)
    break  # í•œ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸í•  ë•ŒëŠ” breakë¡œ í•œë²ˆë§Œ ì‹¤í–‰

# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# í•™ìŠµ ë£¨í”„
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    for X_batch, Y_batch in dataloader:
        optimizer.zero_grad()

        # ì…ë ¥ ì¤€ë¹„
        x_enc = X_batch
        x_mark_enc = torch.ones(x_enc.shape[0], x_enc.shape[1], 1)
        x_dec = torch.zeros(x_enc.shape[0], pred_len, x_enc.shape[2])  # ì˜ˆì¸¡ìš© ì…ë ¥ (0ìœ¼ë¡œ ì±„ì›€)
        x_mark_dec = torch.ones(x_enc.shape[0], pred_len, 1)

        outputs = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
        outputs = outputs[:, :, -1:]

        loss = criterion(outputs, Y_batch)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}")
    
# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
model.eval()

# ì˜ˆì¸¡ ìˆ˜í–‰
with torch.no_grad():
    for X_batch, Y_batch in dataloader:
        x_enc = X_batch
        x_mark_enc = torch.ones(x_enc.shape[0], x_enc.shape[1], 1)
        x_dec = torch.zeros(x_enc.shape[0], pred_len, x_enc.shape[2])
        x_mark_dec = torch.ones(x_enc.shape[0], pred_len, 1)

        # ëª¨ë¸ ì¶œë ¥
        outputs = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
        
        # ë§ˆì§€ë§‰ featureë§Œ ì‚¬ìš© (íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡)
        outputs = outputs[:, :, -1:]  # ì—¬ê¸°ì„œ ìˆ˜ì •!

        break  # ì²« ë²ˆì§¸ ë°°ì¹˜ì— ëŒ€í•œ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
predictions = outputs.numpy()

# ì •ê·œí™”ëœ ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›
predictions_original = target_scaler.inverse_transform(predictions.reshape(-1, 1)).reshape(-1, pred_len, 1)

# ê²°ê³¼ í™•ì¸
#print("ì˜ˆì¸¡ëœ íƒœì–‘ê´‘ ë°œì „ëŸ‰ (ì²« ë²ˆì§¸ ë°°ì¹˜):")
#print(predictions_original)

# 1. ì˜ˆì¸¡ê°’ì„ í‰íƒ„í™”í•´ì„œ í•˜ë‚˜ì˜ 1D ë°°ì—´ë¡œ ë§Œë“¤ì–´ì¤Œ
flattened_preds = predictions_original.reshape(-1)

# 2. ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¶™ì„ ì‹œì : input_len + pred_len ì´í›„ë¶€í„°
start_idx = input_len + pred_len

# 3. df_2013ì— ë§ì¶° ë¹ˆ ê°’(NaN)ìœ¼ë¡œ ì±„ìš´ ì „ì²´ prediction column ìƒì„±
full_preds = np.full(len(df_2013), np.nan)
full_preds[start_idx:start_idx + len(flattened_preds)] = flattened_preds

# 4. df_2013ì— 'prediction' ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
df_2013['prediction'] = full_preds

# ê²°ê³¼ í™•ì¸
print(df_2013[['solar generation', 'prediction']].head(30))

df_2013.to_csv("solar_prediction_2013.csv", index=False, encoding='utf-8-sig')

# NaNì´ ì•„ë‹Œ ë¶€ë¶„ë§Œ ë¹„êµ
valid_idx = ~df_2013['prediction'].isna()
y_true = df_2013.loc[valid_idx, 'solar generation'].values
y_pred = df_2013.loc[valid_idx, 'prediction'].values

# ì •í™•ë„ ì§€í‘œ ê³„ì‚°
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_true, y_pred)

# ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ“Š ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€:")
print(f"MSE  (Mean Squared Error):      {mse:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse:.4f}")
print(f"MAE  (Mean Absolute Error):     {mae:.4f}")